{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Testing out PyTorch Forecasting"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95267dce89811ed"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-22T14:27:38.025952Z",
     "start_time": "2024-03-22T14:27:34.933969Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot create a consistent method resolution\norder (MRO) for bases Callback, PyTorchLightningPruningCallback",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 7\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpytorch_forecasting\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexamples\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_stallion_data\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpytorch_forecasting\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m RMSE, SMAPE\n\u001B[1;32m----> 7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpytorch_forecasting\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtemporal_fusion_transformer\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtuning\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m optimize_hyperparameters\n\u001B[0;32m      9\u001B[0m data \u001B[38;5;241m=\u001B[39m get_stallion_data()\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML_Regression\\.venv\\lib\\site-packages\\pytorch_forecasting\\models\\temporal_fusion_transformer\\tuning.py:29\u001B[0m\n\u001B[0;32m     25\u001B[0m optuna_logger \u001B[38;5;241m=\u001B[39m logging\u001B[38;5;241m.\u001B[39mgetLogger(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moptuna\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     28\u001B[0m \u001B[38;5;66;03m# need to inherit from callback for this to work\u001B[39;00m\n\u001B[1;32m---> 29\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mPyTorchLightningPruningCallbackAdjusted\u001B[39;00m(pl\u001B[38;5;241m.\u001B[39mCallback, PyTorchLightningPruningCallback):\n\u001B[0;32m     30\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m     33\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21moptimize_hyperparameters\u001B[39m(\n\u001B[0;32m     34\u001B[0m     train_dataloaders: DataLoader,\n\u001B[0;32m     35\u001B[0m     val_dataloaders: DataLoader,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     52\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m     53\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m optuna\u001B[38;5;241m.\u001B[39mStudy:\n",
      "\u001B[1;31mTypeError\u001B[0m: Cannot create a consistent method resolution\norder (MRO) for bases Callback, PyTorchLightningPruningCallback"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_forecasting import TimeSeriesDataSet, Baseline, TemporalFusionTransformer, DeepAR\n",
    "from pytorch_forecasting.data import NaNLabelEncoder\n",
    "from pytorch_forecasting.data.examples import get_stallion_data\n",
    "from pytorch_forecasting.metrics import RMSE, SMAPE\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "\n",
    "data = get_stallion_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "data[\"time_idx\"] = data[\"date\"].dt.year * 52 + data[\"date\"].dt.weekofyear\n",
    "data[\"month\"] = data.date.dt.month.astype(str).astype(\"category\")\n",
    "data[\"log_volume\"] = np.log(data.volume + 1e-8)\n",
    "data[\"avg_basket_size\"] = data[\"volume\"] / data[\"order\"]\n",
    "data.fillna(0, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "25aaebaa2f6bf666"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "mask = data[\"time_idx\"] > data[\"time_idx\"].max() - 12 * 2\n",
    "training_data = TimeSeriesDataSet(\n",
    "    data[~mask],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"volume\",\n",
    "    group_ids=[\"agency\", \"sku\"],\n",
    "    min_encoder_length=0,\n",
    "    max_encoder_length=12,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=24,\n",
    "    static_categoricals=[\"agency\", \"sku\", \"brand\"],\n",
    "    static_reals=[\"avg_population_2017\", \"avg_yearly_household_income_2017\"],\n",
    "    time_varying_known_categoricals=[\"special_days\", \"month\"],\n",
    "    variable_groups={\"special_days\": [\"easter_day\", \"good_friday\", \"new_year\", \"christmas\", \"labor_day\"]},\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76d50f005b02c451"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the validation data\n",
    "validation_data = TimeSeriesDataSet.from_dataset(training_data, data[mask], predict=True, stop_randomization=True)\n",
    "\n",
    "# Calculate baseline absolute error\n",
    "actuals = torch.cat([y[0] for x, y in iter(validation_data)], dim=0)\n",
    "baseline_predictions = Baseline().predict(validation_data)\n",
    "(abs(baseline_predictions - actuals).mean().item())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8497146cf8dba89"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# configure network and trainer\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()  # log the learning rate\n",
    "logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,\n",
    "    gpus=1,  # use this to train on GPU\n",
    "    weights_summary=\"top\",\n",
    "    gradient_clip_val=0.1,\n",
    "    limit_train_batches=30,  # running validation every 30 batches\n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    ")\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training_data,\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=32,\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=8,\n",
    "    output_size=7,\n",
    "    loss=QuantileLoss(),  # used QuantileLoss for robust log-transformed training\n",
    "    log_interval=10,\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "trainer.fit(tft, train_dataloader=training_data, val_dataloaders=validation_data)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9fd330227812338"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Predictions are taken on GPU and moved back to CPU --> Speeds up predictions\n",
    "raw_predictions, x = tft.predict(validation_data, mode=\"raw\")\n",
    "\n",
    "final_preds = (raw_predictions[\"prediction\"] * std + mean).detach().numpy().T"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18ae329a0ba6460b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
